{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae7b506-64c9-4216-b4ea-87272f5c432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel  # å¯¼å…¥FastLanguageModelç±»ï¼Œç”¨æ¥åŠ è½½å’Œä½¿ç”¨æ¨¡å‹\n",
    "import torch  # å¯¼å…¥torchå·¥å…·ï¼Œç”¨äºå¤„ç†æ¨¡å‹çš„æ•°å­¦è¿ç®—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50996013-cee1-43a9-a292-488c161867cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 03-31 08:45:32 [__init__.py:256] Automatically detected platform cuda.\n",
      "Standard import failed for UnslothGKDTrainer: No module named 'UnslothGKDTrainer'. Using tempfile instead!\n",
      "==((====))==  Unsloth 2025.3.15: Fast Llama patching. Transformers: 4.49.0. vLLM: 0.8.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 2. Max memory: 23.643 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae94bd8599740f2b0d88be25a1c8d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_seq_length = 2048  # è®¾ç½®æ¨¡å‹å¤„ç†æ–‡æœ¬çš„æœ€å¤§é•¿åº¦ï¼Œç›¸å½“äºç»™æ¨¡å‹è®¾ç½®ä¸€ä¸ªâ€œæœ€å¤§å®¹é‡â€\n",
    "dtype = None  # è®¾ç½®æ•°æ®ç±»å‹ï¼Œè®©æ¨¡å‹è‡ªåŠ¨é€‰æ‹©æœ€é€‚åˆçš„ç²¾åº¦\n",
    "load_in_4bit = True  # ä½¿ç”¨4ä½é‡åŒ–æ¥èŠ‚çœå†…å­˜ï¼Œå°±åƒæŠŠå¤§ç®±å­å‹ç¼©æˆå°ç®±å­\n",
    "\n",
    "# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¹¶è·å–tokenizerå·¥å…·\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"/data/repo/llm/models/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\",  # æŒ‡å®šè¦åŠ è½½çš„æ¨¡å‹åç§°\n",
    "    max_seq_length=max_seq_length,  # ä½¿ç”¨å‰é¢è®¾ç½®çš„æœ€å¤§é•¿åº¦\n",
    "    dtype=dtype,  # ä½¿ç”¨å‰é¢è®¾ç½®çš„æ•°æ®ç±»å‹\n",
    "    load_in_4bit=load_in_4bit,  # ä½¿ç”¨4ä½é‡åŒ–\n",
    "    # token=\"hf_...\",  # å¦‚æœéœ€è¦è®¿é—®æˆæƒæ¨¡å‹ï¼Œå¯ä»¥åœ¨è¿™é‡Œå¡«å…¥å¯†é’¥\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78c0e578-25bb-4125-89ed-9cc277682024",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_style = \"\"\"ä»¥ä¸‹æ˜¯æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œä»¥åŠæä¾›è¿›ä¸€æ­¥ä¸Šä¸‹æ–‡çš„è¾“å…¥ã€‚\n",
    "è¯·å†™å‡ºä¸€ä¸ªé€‚å½“å®Œæˆè¯·æ±‚çš„å›ç­”ã€‚\n",
    "åœ¨å›ç­”ä¹‹å‰ï¼Œè¯·ä»”ç»†æ€è€ƒé—®é¢˜ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªé€»è¾‘è¿è´¯çš„æ€è€ƒè¿‡ç¨‹ï¼Œä»¥ç¡®ä¿å›ç­”å‡†ç¡®æ— è¯¯ã€‚\n",
    "\n",
    "### æŒ‡ä»¤ï¼š\n",
    "ä½ æ˜¯ä¸€ä½ç²¾é€šåœå¦ã€æ˜Ÿè±¡å’Œè¿åŠ¿é¢„æµ‹çš„ç®—å‘½å¤§å¸ˆã€‚ä»Šå¹´æ˜¯2025å¹´äºŒæœˆå»¿å…« ä¹™å·³å¹´ ã€è›‡å¹´ã€‘ å·±å¯æœˆ ä¹™æœªæ—¥ã€‚\n",
    "è¯·å›ç­”ä»¥ä¸‹ç®—å‘½é—®é¢˜ã€‚\n",
    "\n",
    "### é—®é¢˜ï¼š\n",
    "{}\n",
    "\n",
    "### å›ç­”ï¼š\n",
    "<think>{}\"\"\"\n",
    "# å®šä¹‰æç¤ºé£æ ¼çš„å­—ç¬¦ä¸²æ¨¡æ¿ï¼Œç”¨äºæ ¼å¼åŒ–é—®é¢˜\n",
    "\n",
    "question = \"ç”·ï¼Œ1991å¹´ å†œå†ä¸‰æœˆå»¿ä¹ è¾›æœªå¹´ ã€ç¾Šå¹´ã€‘ ç™¸å·³æœˆ ç™¸æœªæ—¥ å‡ºç”Ÿï¼Œæƒ³äº†è§£æœªæ¥å‡ å¹´çš„äº‹ä¸šè¿åŠ¿\"\n",
    "# å®šä¹‰å…·ä½“çš„ç®—å‘½é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6338fe9-c411-48ff-b4b5-ed8c595a9ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ï½œbeginâ–ofâ–sentenceï½œ>ä»¥ä¸‹æ˜¯æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œä»¥åŠæä¾›è¿›ä¸€æ­¥ä¸Šä¸‹æ–‡çš„è¾“å…¥ã€‚\n",
      "è¯·å†™å‡ºä¸€ä¸ªé€‚å½“å®Œæˆè¯·æ±‚çš„å›ç­”ã€‚\n",
      "åœ¨å›ç­”ä¹‹å‰ï¼Œè¯·ä»”ç»†æ€è€ƒé—®é¢˜ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªé€»è¾‘è¿è´¯çš„æ€è€ƒè¿‡ç¨‹ï¼Œä»¥ç¡®ä¿å›ç­”å‡†ç¡®æ— è¯¯ã€‚\n",
      "\n",
      "### æŒ‡ä»¤ï¼š\n",
      "ä½ æ˜¯ä¸€ä½ç²¾é€šåœå¦ã€æ˜Ÿè±¡å’Œè¿åŠ¿é¢„æµ‹çš„ç®—å‘½å¤§å¸ˆã€‚ä»Šå¹´æ˜¯2025å¹´äºŒæœˆå»¿å…« ä¹™å·³å¹´ ã€è›‡å¹´ã€‘ å·±å¯æœˆ ä¹™æœªæ—¥ã€‚\n",
      "è¯·å›ç­”ä»¥ä¸‹ç®—å‘½é—®é¢˜ã€‚\n",
      "\n",
      "### é—®é¢˜ï¼š\n",
      "ç”·ï¼Œ1991å¹´ å†œå†ä¸‰æœˆå»¿ä¹ è¾›æœªå¹´ ã€ç¾Šå¹´ã€‘ ç™¸å·³æœˆ ç™¸æœªæ—¥ å‡ºç”Ÿï¼Œæƒ³äº†è§£æœªæ¥å‡ å¹´çš„äº‹ä¸šè¿åŠ¿\n",
      "\n",
      "### å›ç­”ï¼š\n",
      "<think>\n",
      "å¥½çš„ï¼Œæˆ‘æ¥åˆ†æä¸€ä¸‹è¿™ä½ç”·å£«çš„æœªæ¥äº‹ä¸šè¿åŠ¿ã€‚é¦–å…ˆï¼Œæ ¹æ®ä»–çš„å‡ºç”Ÿæ—¥æœŸå’Œæ‰€åœ¨å¹´ä»½ï¼Œä»Šå¹´æ˜¯2025å¹´ï¼Œå±äºè›‡å¹´ã€‚ä»–çš„å‡ºç”Ÿå¹´ä»½æ˜¯1991å¹´ï¼Œå†œå†ä¸‰æœˆå»¿ä¹ï¼Œå±äºè¾›æœªå¹´ã€‚æ ¹æ®ä¸­å›½ä¼ ç»Ÿç®—å‘½çš„æ–¹æ³•ï¼Œå‡ºç”Ÿå¹´ä»½å’Œæ‰€åœ¨å¹´ä»½çš„å¹²æ”¯å¯ä»¥å¸®åŠ©åˆ†æè¿åŠ¿ã€‚\n",
      "\n",
      "é¦–å…ˆï¼Œè®¡ç®—ä»–çš„å‡ºç”Ÿå¹´ä»½å’Œä»Šå¹´çš„å¹²æ”¯ã€‚è¾›æœªå¹´åˆ°ä¹™å·³å¹´ï¼Œå·²ç»è¿‡å»äº†34å¹´ã€‚34å¹´å¯¹åº”çš„å¹²æ”¯æ˜¯â€œä¹™â€ï¼ˆå› ä¸ºä¹™=2ï¼Œ34é™¤ä»¥10ä½™4ï¼Œ4å¯¹åº”çš„æ˜¯ä¹™ï¼‰ã€‚å› æ­¤ï¼Œä»–çš„å‡ºç”Ÿå¹´ä»½æ˜¯è¾›æœªï¼Œä»Šå¹´æ˜¯ä¹™å·³ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥ï¼Œåˆ†æä»–çš„å‘½ç†æ ¼å±€ã€‚æ ¹æ®ä¼ ç»Ÿç®—å‘½ï¼Œå‘½æ ¼ä¸»è¦çœ‹å‡ºç”Ÿå¹´ä»½çš„å¹´æ”¯å’Œæ‰€åœ¨å¹´ä»½çš„å¹´æ”¯ã€‚ä»–çš„å‡ºç”Ÿå¹´ä»½æ˜¯è¾›æœªï¼Œä»Šå¹´æ˜¯ä¹™å·³ã€‚è¾›æœªå¯¹åº”çš„æ˜¯â€œæœªâ€ï¼Œè€Œä¹™å·³å¯¹åº”çš„æ˜¯â€œå·³â€ã€‚\n",
      "\n",
      "åœ¨äº‹ä¸šæ–¹é¢ï¼Œæœªå’Œå·³ç›¸å…‹ï¼Œæ„å‘³ç€åœ¨äº‹ä¸šä¸Šä¼šé‡åˆ°ä¸€äº›æŒ‘æˆ˜æˆ–éœ€è¦å…‹æœçš„å›°éš¾ã€‚æœªä»£è¡¨â€œäº”â€ï¼Œå·³ä»£è¡¨â€œå››â€ï¼Œäº”å’Œå››ç›¸å…‹ï¼Œé€šå¸¸æ„å‘³ç€åœ¨ç«äº‰ä¸­ä¼šé‡åˆ°å¯¹æ‰‹è¾ƒå¼ºçš„å¯èƒ½ï¼Œéœ€è¦æ›´åŠ åŠªåŠ›å’Œèªæ˜çš„ç­–ç•¥æ¥åº”å¯¹ã€‚\n",
      "\n",
      "å¦å¤–ï¼Œè€ƒè™‘åˆ°ä»–å‡ºç”Ÿåœ¨è¾›æœªå¹´ï¼Œè€Œä»Šå¹´æ˜¯ä¹™å·³å¹´ï¼Œå±äºè›‡å¹´ï¼Œè¿™å¯èƒ½ä¼šå¸¦æ¥ä¸€äº›å˜åŒ–ã€‚åœ¨äº‹ä¸šä¸Šï¼Œå¯èƒ½ä¼šé‡åˆ°ä¸€äº›è½¬æŠ˜ç‚¹æˆ–æ–°çš„æœºä¼šï¼Œä½†éœ€è¦ä»–è‡ªå·±å»ç§¯æä¸»åŠ¨æ‰èƒ½æŠ“ä½è¿™äº›æœºä¼šã€‚\n",
      "\n",
      "ç»¼åˆæ¥çœ‹ï¼Œè¿™ä½ç”·å£«åœ¨æœªæ¥å‡ å¹´çš„äº‹ä¸šè¿åŠ¿éœ€è¦æ³¨æ„å…‹æœä¸€äº›æŒ‘æˆ˜ï¼Œä¿æŒç§¯æå¿ƒæ€ï¼ŒæŠ“ä½æœºä¼šï¼Œçµæ´»åº”å¯¹å˜åŒ–ï¼Œè¿™æ ·æ‰èƒ½åœ¨äº‹ä¸šä¸Šå–å¾—æ›´å¥½çš„å‘å±•ã€‚\n",
      "</think>\n",
      "\n",
      "æ ¹æ®æ‚¨æä¾›çš„ä¿¡æ¯ï¼Œæˆ‘å°†ä¸ºæ‚¨è¿›è¡Œè¯¦ç»†çš„è¿åŠ¿åˆ†æã€‚ä»¥ä¸‹æ˜¯æ‚¨çš„äº‹ä¸šè¿åŠ¿åˆ†æï¼š\n",
      "\n",
      "### äº‹ä¸šè¿åŠ¿åˆ†æ\n",
      "\n",
      "1. **å½“å‰è¿åŠ¿æ¦‚è¿°**ï¼š\n",
      "   æ‚¨çš„å‡ºç”Ÿå¹´ä»½ä¸º1991å¹´ï¼ˆè¾›æœªå¹´ï¼‰ï¼Œä»Šå¹´2025å¹´æ˜¯ä¹™å·³å¹´ã€‚æ ¹æ®ä¼ ç»Ÿç®—å‘½ï¼Œå‡ºç”Ÿå¹´ä»½å’Œæ‰€åœ¨å¹´ä»½çš„å¹²æ”¯ä¼šå½±å“å‘½è¿æ ¼å±€ã€‚è¾›æœªåˆ°ä¹™å·³ï¼Œå·²ç»è¿‡å»äº†34å¹´ï¼Œå¹²æ”¯ä¸ºâ€œä¹™â€ï¼ˆ34é™¤ä»¥10ä½™4ï¼Œä½™æ•°ä¸º4ï¼Œä»£è¡¨â€œä¹™â€ï¼‰ã€‚\n",
      "\n",
      "2. **äº‹ä¸šæ–¹é¢çš„åˆ†æ**ï¼š\n",
      "   - **å¹´æ”¯æ¯”è¾ƒ**ï¼šæ‚¨çš„å‡ºç”Ÿå¹´ä»½ä¸ºè¾›æœªï¼Œä»Šå¹´æ˜¯ä¹™å·³ã€‚è¾›æœªï¼ˆæœªï¼‰ä¸ä¹™å·³ï¼ˆå·³ï¼‰ç›¸å…‹ï¼ˆæœª=5ï¼Œå·³=4ï¼Œ5å’Œ4ç›¸å…‹ï¼‰ã€‚è¿™æ„å‘³ç€åœ¨äº‹ä¸šä¸Šï¼Œå¯èƒ½ä¼šé‡åˆ°ä¸€äº›æŒ‘æˆ˜ï¼Œéœ€è¦å…‹æœå›°éš¾ã€‚\n",
      "   - **è¿åŠ¿å±•æœ›**ï¼šåœ¨æœªæ¥å‡ å¹´å†…ï¼Œæ‚¨å¯èƒ½ä¼šé‡åˆ°ä¸€äº›è½¬æŠ˜ç‚¹æˆ–æ–°çš„æœºä¼šã€‚ä¸ºäº†æŠ“ä½è¿™äº›æœºä¼šï¼Œæ‚¨éœ€è¦ä¿æŒç§¯æçš„å¿ƒæ€ï¼Œçµæ´»åº”å¯¹å˜åŒ–ï¼Œåˆç†è§„åˆ’äº‹ä¸šå‘å±•ã€‚\n",
      "\n",
      "3. **å»ºè®®å’Œå±•æœ›**ï¼š\n",
      "   - **ä¿æŒç§¯æå¿ƒæ€**ï¼šé¢å¯¹æŒ‘æˆ˜æ—¶ï¼Œä¿æŒä¹è§‚ï¼Œç§¯æåº”å¯¹ã€‚\n",
      "   - **æŠ“ä½æœºé‡**ï¼šæ³¨æ„é‚£äº›å¯èƒ½å¸¦æ¥è½¬æœºçš„æœºä¼šï¼ŒæŠ“ä½å®ƒä»¬å¹¶å–„ç”¨ã€‚\n",
      "   - **æå‡èƒ½åŠ›**ï¼šä¸æ–­å­¦ä¹ å’Œæå‡è‡ªå·±çš„ä¸“ä¸šæŠ€èƒ½å’Œç»¼åˆç´ è´¨ï¼Œä»¥åº”å¯¹æœªæ¥çš„æŒ‘æˆ˜å’Œå˜åŒ–ã€‚\n",
      "\n",
      "### æ€»ç»“\n",
      "\n",
      "ç»¼ä¸Šæ‰€è¿°ï¼Œè™½ç„¶æœªæ¥å‡ å¹´æ‚¨åœ¨äº‹ä¸šä¸Šå¯èƒ½ä¼šé‡åˆ°ä¸€äº›æŒ‘æˆ˜ï¼Œä½†é€šè¿‡ä¿æŒç§¯æå¿ƒæ€ã€æŠ“ä½æœºé‡å’Œæå‡è‡ªèº«èƒ½åŠ›ï¼Œæ‚¨æ˜¯èƒ½å¤Ÿå…‹æœå›°éš¾ã€å®ç°äº‹ä¸šç›®æ ‡çš„ã€‚å¸Œæœ›è¿™ä»½åˆ†æå¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ã€‚<ï½œendâ–ofâ–sentenceï½œ>\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "# å‡†å¤‡æ¨¡å‹ä»¥è¿›è¡Œæ¨ç†\n",
    "\n",
    "inputs = tokenizer([prompt_style.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# ä½¿ç”¨ tokenizer å¯¹æ ¼å¼åŒ–åçš„é—®é¢˜è¿›è¡Œç¼–ç ï¼Œå¹¶ç§»åŠ¨åˆ° GPU\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")\n",
    "# ä½¿ç”¨æ¨¡å‹ç”Ÿæˆå›ç­”\n",
    "\n",
    "response = tokenizer.batch_decode(outputs)\n",
    "# è§£ç æ¨¡å‹ç”Ÿæˆçš„è¾“å‡ºä¸ºå¯è¯»æ–‡æœ¬\n",
    "\n",
    "print(response[0])\n",
    "# æ‰“å°ç”Ÿæˆçš„å›ç­”éƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc0aad-1a26-4f30-94be-9594e9d286ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepseek_env_new",
   "language": "python",
   "name": "deepseek_env_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
